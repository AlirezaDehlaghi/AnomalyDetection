{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff501730-7ce8-4e10-aef8-7b233002d8ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Dataset and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - RISE\\Code Repo\\AnomalyDetection\\Interpreter\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming your dataset is in a CSV file named 'Dataset.csv'\n",
    "data = pd.read_csv('input/Dataset.csv')\n",
    "# Process Data\n",
    "\n",
    "# Preprocess Labels\n",
    "label_column = ['NST_M_Label']\n",
    "label_columns_all = ['IT_B_Label', 'IT_M_Label', 'NST_B_Label', 'NST_M_Label']\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(data[label_column])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = pd.get_dummies(y_encoded).values\n",
    "\n",
    "# Drop all label columns\n",
    "data = data.drop(columns=label_columns_all)\n",
    "\n",
    "\n",
    "# Preprocess Data\n",
    "\n",
    "from ColumnDropperTransformer import ColumnDropperTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "unused_columns = ['sAddress', 'rAddress', 'sMACs', 'rMACs', 'sIPs', 'rIPs', 'startDate', 'endDate', 'start', 'end', 'startOffset', 'endOffset']\n",
    "categorical_columns = ['protocol']\n",
    "\n",
    "categorial_transformer = ColumnTransformer(\n",
    "    [\n",
    "        # Due to some indexing problem categorical_columns = ['protocol'] transfered via [0] index of 0\n",
    "        ('ohe_encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'),[0])\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('drop_unused' , ColumnDropperTransformer(unused_columns)),\n",
    "    ('fill_missing', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('transform_categorial',categorial_transformer),\n",
    "    ('normalizer', StandardScaler())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y_one_hot, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Test with predefined model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9782370953630796\n",
      "Confusion Matrix:\n",
      "[[7327    0    3    6    5    0]\n",
      " [   2  385    0    0    0    0]\n",
      " [   0    0   32    0    6    0]\n",
      " [   5    0   18  484    9    1]\n",
      " [  16    0   32    1  340    0]\n",
      " [  46    0    7   39    3  377]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from ModelCreator import create_model\n",
    "\n",
    "model = KerasClassifier(model=create_model, input_dim=X_train.shape[1], output_dim=y_train.shape[1], hidden_layer_size = 128, epochs=10, batch_size=32, verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred_classes)\n",
    "conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred_classes)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search for best parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3382 - accuracy: 0.9044 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1442 - accuracy: 0.9544 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1152 - accuracy: 0.9624 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0973 - accuracy: 0.9650 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0858 - accuracy: 0.9665 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0770 - accuracy: 0.9719 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 2s - loss: 0.0712 - accuracy: 0.9754 - 2s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0665 - accuracy: 0.9767 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0637 - accuracy: 0.9778 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0627 - accuracy: 0.9775 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 615ms/epoch - 2ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=32; total time=  14.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3366 - accuracy: 0.9084 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1509 - accuracy: 0.9530 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1193 - accuracy: 0.9631 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0989 - accuracy: 0.9634 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0859 - accuracy: 0.9671 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0764 - accuracy: 0.9728 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0701 - accuracy: 0.9747 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0663 - accuracy: 0.9752 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0643 - accuracy: 0.9756 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0604 - accuracy: 0.9774 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 677ms/epoch - 2ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=32; total time=  15.3s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3959 - accuracy: 0.8873 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1574 - accuracy: 0.9468 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1234 - accuracy: 0.9615 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1053 - accuracy: 0.9629 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0932 - accuracy: 0.9640 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0838 - accuracy: 0.9676 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0763 - accuracy: 0.9725 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0719 - accuracy: 0.9745 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0679 - accuracy: 0.9753 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0661 - accuracy: 0.9754 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 480ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=32; total time=  13.5s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2590 - accuracy: 0.9252 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1270 - accuracy: 0.9621 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1018 - accuracy: 0.9647 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 2s - loss: 0.0852 - accuracy: 0.9673 - 2s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 2s - loss: 0.0742 - accuracy: 0.9744 - 2s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0674 - accuracy: 0.9768 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0625 - accuracy: 0.9776 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0602 - accuracy: 0.9779 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0587 - accuracy: 0.9777 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0560 - accuracy: 0.9788 - 1s/epoch - 1ms/step\n",
      "381/381 - 1s - 525ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=64; total time=  13.1s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2737 - accuracy: 0.9184 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1325 - accuracy: 0.9603 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1047 - accuracy: 0.9620 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0854 - accuracy: 0.9673 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0738 - accuracy: 0.9740 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0672 - accuracy: 0.9758 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0639 - accuracy: 0.9761 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0622 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0596 - accuracy: 0.9772 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0578 - accuracy: 0.9765 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 418ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=64; total time=  11.8s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2827 - accuracy: 0.9189 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1263 - accuracy: 0.9600 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0976 - accuracy: 0.9628 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0804 - accuracy: 0.9697 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0714 - accuracy: 0.9753 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0664 - accuracy: 0.9755 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0629 - accuracy: 0.9763 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0600 - accuracy: 0.9767 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0586 - accuracy: 0.9775 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0572 - accuracy: 0.9781 - 1s/epoch - 2ms/step\n",
      "381/381 - 0s - 440ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=64; total time=  11.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2322 - accuracy: 0.9350 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1118 - accuracy: 0.9632 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0867 - accuracy: 0.9675 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0744 - accuracy: 0.9742 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0653 - accuracy: 0.9769 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0622 - accuracy: 0.9771 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0606 - accuracy: 0.9779 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0575 - accuracy: 0.9784 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0555 - accuracy: 0.9788 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0543 - accuracy: 0.9795 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 439ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=128; total time=  11.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2253 - accuracy: 0.9357 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1134 - accuracy: 0.9624 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0888 - accuracy: 0.9652 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0730 - accuracy: 0.9738 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0674 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0629 - accuracy: 0.9765 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0603 - accuracy: 0.9772 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0574 - accuracy: 0.9767 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0555 - accuracy: 0.9778 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0539 - accuracy: 0.9771 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 568ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=128; total time=  12.6s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2273 - accuracy: 0.9353 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1131 - accuracy: 0.9623 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0886 - accuracy: 0.9657 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0740 - accuracy: 0.9734 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0680 - accuracy: 0.9761 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0641 - accuracy: 0.9766 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0612 - accuracy: 0.9775 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0590 - accuracy: 0.9767 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0557 - accuracy: 0.9781 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0560 - accuracy: 0.9784 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 475ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=128; total time=  12.0s\n",
      "Epoch 1/10\n",
      "762/762 - 1s - loss: 0.3143 - accuracy: 0.9158 - 1s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1435 - accuracy: 0.9536 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1059 - accuracy: 0.9637 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0880 - accuracy: 0.9705 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0772 - accuracy: 0.9759 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0715 - accuracy: 0.9767 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0673 - accuracy: 0.9770 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0635 - accuracy: 0.9781 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0602 - accuracy: 0.9786 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0582 - accuracy: 0.9790 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 424ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=32; total time=  11.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3450 - accuracy: 0.9022 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1454 - accuracy: 0.9512 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1053 - accuracy: 0.9626 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0848 - accuracy: 0.9709 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0747 - accuracy: 0.9750 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0684 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0646 - accuracy: 0.9764 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0618 - accuracy: 0.9770 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0596 - accuracy: 0.9775 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0574 - accuracy: 0.9785 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 428ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=32; total time=  11.5s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3425 - accuracy: 0.9075 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1457 - accuracy: 0.9516 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1048 - accuracy: 0.9636 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0874 - accuracy: 0.9694 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0771 - accuracy: 0.9736 - 1000ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0716 - accuracy: 0.9754 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0672 - accuracy: 0.9755 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0643 - accuracy: 0.9762 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0617 - accuracy: 0.9770 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0600 - accuracy: 0.9780 - 986ms/epoch - 1ms/step\n",
      "381/381 - 0s - 433ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=32; total time=  11.3s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2701 - accuracy: 0.9250 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1132 - accuracy: 0.9614 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0861 - accuracy: 0.9699 - 996ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0747 - accuracy: 0.9750 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0691 - accuracy: 0.9760 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0645 - accuracy: 0.9771 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0617 - accuracy: 0.9776 - 989ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0591 - accuracy: 0.9785 - 995ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0575 - accuracy: 0.9791 - 996ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0561 - accuracy: 0.9787 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 606ms/epoch - 2ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=64; total time=  11.8s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2823 - accuracy: 0.9188 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1226 - accuracy: 0.9578 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0927 - accuracy: 0.9668 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 2s - loss: 0.0783 - accuracy: 0.9736 - 2s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 2s - loss: 0.0706 - accuracy: 0.9753 - 2s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0658 - accuracy: 0.9759 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0623 - accuracy: 0.9765 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 2s - loss: 0.0606 - accuracy: 0.9762 - 2s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0574 - accuracy: 0.9781 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0558 - accuracy: 0.9776 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 552ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=64; total time=  15.0s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2868 - accuracy: 0.9167 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1220 - accuracy: 0.9584 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0900 - accuracy: 0.9670 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0760 - accuracy: 0.9732 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0687 - accuracy: 0.9760 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0644 - accuracy: 0.9765 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0618 - accuracy: 0.9768 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0596 - accuracy: 0.9777 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0580 - accuracy: 0.9779 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0562 - accuracy: 0.9788 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 436ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=64; total time=  12.1s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2290 - accuracy: 0.9323 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1058 - accuracy: 0.9626 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0808 - accuracy: 0.9723 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0704 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0648 - accuracy: 0.9764 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0617 - accuracy: 0.9785 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0586 - accuracy: 0.9780 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0562 - accuracy: 0.9792 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0546 - accuracy: 0.9788 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0539 - accuracy: 0.9795 - 1s/epoch - 1ms/step\n",
      "381/381 - 1s - 768ms/epoch - 2ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=128; total time=  12.5s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2358 - accuracy: 0.9300 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1100 - accuracy: 0.9617 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0837 - accuracy: 0.9706 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0738 - accuracy: 0.9734 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0678 - accuracy: 0.9747 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0634 - accuracy: 0.9768 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0608 - accuracy: 0.9767 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0585 - accuracy: 0.9771 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0570 - accuracy: 0.9776 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0548 - accuracy: 0.9778 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 453ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=128; total time=  12.2s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2364 - accuracy: 0.9312 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1116 - accuracy: 0.9608 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0854 - accuracy: 0.9702 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0740 - accuracy: 0.9737 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0680 - accuracy: 0.9754 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0631 - accuracy: 0.9759 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0604 - accuracy: 0.9772 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0585 - accuracy: 0.9771 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0578 - accuracy: 0.9776 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0563 - accuracy: 0.9769 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 440ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=128; total time=  12.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.4857 - accuracy: 0.8411 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2256 - accuracy: 0.9321 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1930 - accuracy: 0.9335 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1679 - accuracy: 0.9374 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1453 - accuracy: 0.9500 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1248 - accuracy: 0.9580 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.1084 - accuracy: 0.9619 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0956 - accuracy: 0.9647 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0866 - accuracy: 0.9682 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0800 - accuracy: 0.9719 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 438ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=32; total time=  11.6s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3855 - accuracy: 0.8989 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2173 - accuracy: 0.9323 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1835 - accuracy: 0.9347 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1582 - accuracy: 0.9438 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1362 - accuracy: 0.9537 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1180 - accuracy: 0.9601 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.1038 - accuracy: 0.9624 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0929 - accuracy: 0.9644 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0851 - accuracy: 0.9681 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0791 - accuracy: 0.9722 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 436ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=32; total time=  11.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3957 - accuracy: 0.8928 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2257 - accuracy: 0.9307 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1917 - accuracy: 0.9324 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1657 - accuracy: 0.9384 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1416 - accuracy: 0.9528 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1216 - accuracy: 0.9589 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.1058 - accuracy: 0.9636 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0943 - accuracy: 0.9658 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0861 - accuracy: 0.9681 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0794 - accuracy: 0.9717 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 445ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=32; total time=  11.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3455 - accuracy: 0.8992 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1981 - accuracy: 0.9329 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1635 - accuracy: 0.9408 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1358 - accuracy: 0.9539 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1140 - accuracy: 0.9607 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0974 - accuracy: 0.9650 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0861 - accuracy: 0.9687 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0785 - accuracy: 0.9732 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0730 - accuracy: 0.9754 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0691 - accuracy: 0.9767 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 449ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=64; total time=  12.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3253 - accuracy: 0.9092 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1954 - accuracy: 0.9338 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1616 - accuracy: 0.9425 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1343 - accuracy: 0.9544 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1129 - accuracy: 0.9609 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0977 - accuracy: 0.9633 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0880 - accuracy: 0.9678 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0807 - accuracy: 0.9713 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0755 - accuracy: 0.9736 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0719 - accuracy: 0.9739 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 440ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=64; total time=  12.0s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2970 - accuracy: 0.9105 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1841 - accuracy: 0.9338 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1499 - accuracy: 0.9488 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1242 - accuracy: 0.9586 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1056 - accuracy: 0.9626 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0927 - accuracy: 0.9647 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0836 - accuracy: 0.9682 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0767 - accuracy: 0.9721 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0721 - accuracy: 0.9739 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0683 - accuracy: 0.9755 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 445ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=64; total time=  11.7s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3175 - accuracy: 0.9018 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1826 - accuracy: 0.9338 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1482 - accuracy: 0.9478 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1224 - accuracy: 0.9578 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1030 - accuracy: 0.9625 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0897 - accuracy: 0.9680 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0811 - accuracy: 0.9722 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0748 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0705 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0674 - accuracy: 0.9764 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 467ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=128; total time=  12.3s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3394 - accuracy: 0.8960 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1852 - accuracy: 0.9332 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1511 - accuracy: 0.9456 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1243 - accuracy: 0.9566 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1040 - accuracy: 0.9624 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0904 - accuracy: 0.9669 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0812 - accuracy: 0.9703 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0752 - accuracy: 0.9730 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0707 - accuracy: 0.9744 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0679 - accuracy: 0.9753 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 489ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=128; total time=  12.9s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3201 - accuracy: 0.9006 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1820 - accuracy: 0.9346 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1475 - accuracy: 0.9498 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1219 - accuracy: 0.9585 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1032 - accuracy: 0.9625 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0904 - accuracy: 0.9655 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0818 - accuracy: 0.9694 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0755 - accuracy: 0.9721 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0707 - accuracy: 0.9749 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0672 - accuracy: 0.9749 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 437ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=128; total time=  12.2s\n",
      "Epoch 1/10\n",
      "1143/1143 - 2s - loss: 0.2140 - accuracy: 0.9356 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "1143/1143 - 2s - loss: 0.0988 - accuracy: 0.9655 - 2s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1143/1143 - 2s - loss: 0.0763 - accuracy: 0.9740 - 2s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1143/1143 - 2s - loss: 0.0677 - accuracy: 0.9759 - 2s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "1143/1143 - 2s - loss: 0.0626 - accuracy: 0.9766 - 2s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1143/1143 - 2s - loss: 0.0589 - accuracy: 0.9780 - 2s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1143/1143 - 2s - loss: 0.0571 - accuracy: 0.9782 - 2s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1143/1143 - 2s - loss: 0.0552 - accuracy: 0.9786 - 2s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1143/1143 - 2s - loss: 0.0539 - accuracy: 0.9786 - 2s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1143/1143 - 2s - loss: 0.0524 - accuracy: 0.9796 - 2s/epoch - 1ms/step\n",
      "Best Hyperparameters: {'model__activation': 'tanh', 'model__hidden_layer_size': 64}\n",
      "286/286 - 0s - 354ms/epoch - 1ms/step\n",
      "Test Accuracy: 0.9796587926509186\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from ModelCreator import create_model\n",
    "\n",
    "\n",
    "model = KerasClassifier(model=create_model, input_dim=X_train.shape[1], output_dim=y_train.shape[1], epochs=10, batch_size=32, verbose=2)\n",
    "param_grid = {\n",
    "    'model__hidden_layer_size': [32, 64, 128],\n",
    "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    # 'model__alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_result.best_params_}\")\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Inverse transform one-hot encoded predictions to original labels\n",
    "# y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred_classes)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmp40pf16tv\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmp40pf16tv\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmp70ks0rje\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmp70ks0rje\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": "['output/predict_model.joblib']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming 'model' is your Keras model\n",
    "joblib.dump(best_model, 'output/keras_classifier_model.joblib')\n",
    "predict_model_pipeline = Pipeline([\n",
    "    ('preprocess',preprocess),\n",
    "    ('prediction' , best_model)\n",
    "])\n",
    "joblib.dump(predict_model_pipeline, 'output/predict_model.joblib')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Saved Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429/1429 - 2s - 2s/epoch - 2ms/step\n",
      "Test Accuracy: 0.9800516208058095\n",
      "Confusion Matrix:\n",
      "[[36667     0     8    17     7     7]\n",
      " [    1  1933     0     0     0     0]\n",
      " [    0     0   144    24    24     0]\n",
      " [   26     0    97  2437    16     8]\n",
      " [  119     0   128    21  1676     0]\n",
      " [  143     0    51   207     8  1949]]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from ModelCreator import create_model\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('input/Dataset.csv')\n",
    "label_columns_all = ['IT_B_Label', 'IT_M_Label', 'NST_B_Label', 'NST_M_Label']\n",
    "# Encode labels to numerical values\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(data['NST_M_Label'])\n",
    "y_one_hot = pd.get_dummies(y_encoded).values\n",
    "\n",
    "data = data.drop(columns=label_columns_all)\n",
    "\n",
    "model = joblib.load('output/predict_model.joblib')\n",
    "\n",
    "y_pred = model.predict(data)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_one_hot.argmax(axis=1), y_pred_classes)\n",
    "conf_matrix = confusion_matrix(y_one_hot.argmax(axis=1), y_pred_classes)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}