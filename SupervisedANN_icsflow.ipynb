{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff501730-7ce8-4e10-aef8-7b233002d8ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954f876b-92e9-4dc1-841e-5a748ecde5ac",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('input/Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process Labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "           sAddress      rAddress              sMACs              rMACs  \\\n0      192.168.0.11  192.168.0.21  02:42:c0:a8:00:0b  02:42:c0:a8:00:15   \n1      192.168.0.12  192.168.0.21  02:42:c0:a8:00:0c  02:42:c0:a8:00:15   \n2      192.168.0.11  192.168.0.12  02:42:c0:a8:00:0b  02:42:c0:a8:00:0c   \n3      192.168.0.11  192.168.0.12  02:42:c0:a8:00:0b  02:42:c0:a8:00:0c   \n4      192.168.0.11  192.168.0.21  02:42:c0:a8:00:0b  02:42:c0:a8:00:15   \n...             ...           ...                ...                ...   \n45713  192.168.0.22  192.168.0.41  02:42:c0:a8:00:16  02:42:c0:a8:00:29   \n45714  192.168.0.11  192.168.0.41  02:42:c0:a8:00:0b  02:42:c0:a8:00:29   \n45715  192.168.0.12  192.168.0.41  02:42:c0:a8:00:0c  02:42:c0:a8:00:29   \n45716  192.168.0.21  192.168.0.41  02:42:c0:a8:00:15  02:42:c0:a8:00:29   \n45717  192.168.0.23  192.168.0.41  02:42:c0:a8:00:17  02:42:c0:a8:00:29   \n\n               sIPs          rIPs   protocol                   startDate  \\\n0      192.168.0.11  192.168.0.21   IPV4-TCP  2022-09-16 11:14:39.510337   \n1      192.168.0.12  192.168.0.21   IPV4-TCP  2022-09-16 11:14:39.513421   \n2      192.168.0.11  192.168.0.12   IPV4-TCP  2022-09-16 11:14:39.601160   \n3      192.168.0.11  192.168.0.12   IPV4-TCP  2022-09-16 11:14:40.200719   \n4      192.168.0.11  192.168.0.21   IPV4-TCP  2022-09-16 11:14:40.010348   \n...             ...           ...        ...                         ...   \n45713  192.168.0.22  192.168.0.41   IPV4-TCP  2022-09-16 13:23:30.589943   \n45714  192.168.0.11  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:01.401338   \n45715  192.168.0.12  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:01.401604   \n45716  192.168.0.21  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:03.511387   \n45717  192.168.0.23  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:05.744681   \n\n                          endDate         start  ...  sAckDelayMax  \\\n0      2022-09-16 11:14:40.010330  1.663320e+09  ...         0.001   \n1      2022-09-16 11:14:40.013394  1.663320e+09  ...         0.000   \n2      2022-09-16 11:14:40.054139  1.663320e+09  ...         0.198   \n3      2022-09-16 11:14:40.602902  1.663320e+09  ...         0.197   \n4      2022-09-16 11:14:40.507654  1.663320e+09  ...         0.000   \n...                           ...           ...  ...           ...   \n45713  2022-09-16 13:23:30.877939  1.663327e+09  ...         0.000   \n45714  2022-09-16 13:11:01.401338  1.663327e+09  ...           NaN   \n45715  2022-09-16 13:11:01.401604  1.663327e+09  ...           NaN   \n45716  2022-09-16 13:11:03.511387  1.663327e+09  ...           NaN   \n45717  2022-09-16 13:11:05.744681  1.663327e+09  ...           NaN   \n\n       rAckDelayMax  sAckDelayMin  rAckDelayMin  sAckDelayAvg  rAckDelayAvg  \\\n0             0.497           0.0           0.0      0.000219      0.031154   \n1             0.497           0.0           0.0      0.000126      0.027727   \n2             0.200           0.0           0.0      0.023117      0.030055   \n3             0.200           0.0           0.0      0.020180      0.028530   \n4             0.493           0.0           0.0      0.000094      0.017102   \n...             ...           ...           ...           ...           ...   \n45713           NaN           0.0           NaN      0.000007           NaN   \n45714           NaN           NaN           NaN           NaN           NaN   \n45715           NaN           NaN           NaN           NaN           NaN   \n45716           NaN           NaN           NaN           NaN           NaN   \n45717           NaN           NaN           NaN           NaN           NaN   \n\n       IT_B_Label  IT_M_Label  NST_B_Label  NST_M_Label  \n0               0      Normal            0       Normal  \n1               0      Normal            0       Normal  \n2               0      Normal            0       Normal  \n3               0      Normal            0       Normal  \n4               0      Normal            0       Normal  \n...           ...         ...          ...          ...  \n45713           1   port-scan            1    port-scan  \n45714           1      replay            1       replay  \n45715           1      replay            1       replay  \n45716           1      replay            1       replay  \n45717           1      replay            1       replay  \n\n[45718 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sAddress</th>\n      <th>rAddress</th>\n      <th>sMACs</th>\n      <th>rMACs</th>\n      <th>sIPs</th>\n      <th>rIPs</th>\n      <th>protocol</th>\n      <th>startDate</th>\n      <th>endDate</th>\n      <th>start</th>\n      <th>...</th>\n      <th>sAckDelayMax</th>\n      <th>rAckDelayMax</th>\n      <th>sAckDelayMin</th>\n      <th>rAckDelayMin</th>\n      <th>sAckDelayAvg</th>\n      <th>rAckDelayAvg</th>\n      <th>IT_B_Label</th>\n      <th>IT_M_Label</th>\n      <th>NST_B_Label</th>\n      <th>NST_M_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:39.510337</td>\n      <td>2022-09-16 11:14:40.010330</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>0.497</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000219</td>\n      <td>0.031154</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>192.168.0.12</td>\n      <td>192.168.0.21</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>192.168.0.12</td>\n      <td>192.168.0.21</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:39.513421</td>\n      <td>2022-09-16 11:14:40.013394</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.497</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000126</td>\n      <td>0.027727</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:39.601160</td>\n      <td>2022-09-16 11:14:40.054139</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>0.198</td>\n      <td>0.200</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.023117</td>\n      <td>0.030055</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:40.200719</td>\n      <td>2022-09-16 11:14:40.602902</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>0.197</td>\n      <td>0.200</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.020180</td>\n      <td>0.028530</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:40.010348</td>\n      <td>2022-09-16 11:14:40.507654</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.493</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000094</td>\n      <td>0.017102</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>0</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45713</th>\n      <td>192.168.0.22</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:16</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.22</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 13:23:30.589943</td>\n      <td>2022-09-16 13:23:30.877939</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.000007</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>port-scan</td>\n      <td>1</td>\n      <td>port-scan</td>\n    </tr>\n    <tr>\n      <th>45714</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:01.401338</td>\n      <td>2022-09-16 13:11:01.401338</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>replay</td>\n      <td>1</td>\n      <td>replay</td>\n    </tr>\n    <tr>\n      <th>45715</th>\n      <td>192.168.0.12</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.12</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:01.401604</td>\n      <td>2022-09-16 13:11:01.401604</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>replay</td>\n      <td>1</td>\n      <td>replay</td>\n    </tr>\n    <tr>\n      <th>45716</th>\n      <td>192.168.0.21</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.21</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:03.511387</td>\n      <td>2022-09-16 13:11:03.511387</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>replay</td>\n      <td>1</td>\n      <td>replay</td>\n    </tr>\n    <tr>\n      <th>45717</th>\n      <td>192.168.0.23</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:17</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.23</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:05.744681</td>\n      <td>2022-09-16 13:11:05.744681</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>replay</td>\n      <td>1</td>\n      <td>replay</td>\n    </tr>\n  </tbody>\n</table>\n<p>45718 rows × 64 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - RISE\\Code Repo\\AnomalyDetection\\Interpreter\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "           sAddress      rAddress              sMACs              rMACs  \\\n0      192.168.0.11  192.168.0.21  02:42:c0:a8:00:0b  02:42:c0:a8:00:15   \n1      192.168.0.12  192.168.0.21  02:42:c0:a8:00:0c  02:42:c0:a8:00:15   \n2      192.168.0.11  192.168.0.12  02:42:c0:a8:00:0b  02:42:c0:a8:00:0c   \n3      192.168.0.11  192.168.0.12  02:42:c0:a8:00:0b  02:42:c0:a8:00:0c   \n4      192.168.0.11  192.168.0.21  02:42:c0:a8:00:0b  02:42:c0:a8:00:15   \n...             ...           ...                ...                ...   \n45713  192.168.0.22  192.168.0.41  02:42:c0:a8:00:16  02:42:c0:a8:00:29   \n45714  192.168.0.11  192.168.0.41  02:42:c0:a8:00:0b  02:42:c0:a8:00:29   \n45715  192.168.0.12  192.168.0.41  02:42:c0:a8:00:0c  02:42:c0:a8:00:29   \n45716  192.168.0.21  192.168.0.41  02:42:c0:a8:00:15  02:42:c0:a8:00:29   \n45717  192.168.0.23  192.168.0.41  02:42:c0:a8:00:17  02:42:c0:a8:00:29   \n\n               sIPs          rIPs   protocol                   startDate  \\\n0      192.168.0.11  192.168.0.21   IPV4-TCP  2022-09-16 11:14:39.510337   \n1      192.168.0.12  192.168.0.21   IPV4-TCP  2022-09-16 11:14:39.513421   \n2      192.168.0.11  192.168.0.12   IPV4-TCP  2022-09-16 11:14:39.601160   \n3      192.168.0.11  192.168.0.12   IPV4-TCP  2022-09-16 11:14:40.200719   \n4      192.168.0.11  192.168.0.21   IPV4-TCP  2022-09-16 11:14:40.010348   \n...             ...           ...        ...                         ...   \n45713  192.168.0.22  192.168.0.41   IPV4-TCP  2022-09-16 13:23:30.589943   \n45714  192.168.0.11  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:01.401338   \n45715  192.168.0.12  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:01.401604   \n45716  192.168.0.21  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:03.511387   \n45717  192.168.0.23  192.168.0.41  IPV4-ICMP  2022-09-16 13:11:05.744681   \n\n                          endDate         start  ...  sWinTCP  rWinTCP  \\\n0      2022-09-16 11:14:40.010330  1.663320e+09  ...   509.00    502.0   \n1      2022-09-16 11:14:40.013394  1.663320e+09  ...   509.00    502.0   \n2      2022-09-16 11:14:40.054139  1.663320e+09  ...   503.05    506.2   \n3      2022-09-16 11:14:40.602902  1.663320e+09  ...   503.00    506.2   \n4      2022-09-16 11:14:40.507654  1.663320e+09  ...   509.00    502.0   \n...                           ...           ...  ...      ...      ...   \n45713  2022-09-16 13:23:30.877939  1.663327e+09  ...     0.00   1024.0   \n45714  2022-09-16 13:11:01.401338  1.663327e+09  ...      NaN      NaN   \n45715  2022-09-16 13:11:01.401604  1.663327e+09  ...      NaN      NaN   \n45716  2022-09-16 13:11:03.511387  1.663327e+09  ...      NaN      NaN   \n45717  2022-09-16 13:11:05.744681  1.663327e+09  ...      NaN      NaN   \n\n       sFragmentRate  rFragmentRate  sAckDelayMax  rAckDelayMax  sAckDelayMin  \\\n0                0.0            0.0         0.001         0.497           0.0   \n1                0.0            0.0         0.000         0.497           0.0   \n2                0.0            0.0         0.198         0.200           0.0   \n3                0.0            0.0         0.197         0.200           0.0   \n4                0.0            0.0         0.000         0.493           0.0   \n...              ...            ...           ...           ...           ...   \n45713            0.0            0.0         0.000           NaN           0.0   \n45714            NaN            0.0           NaN           NaN           NaN   \n45715            NaN            0.0           NaN           NaN           NaN   \n45716            NaN            0.0           NaN           NaN           NaN   \n45717            NaN            0.0           NaN           NaN           NaN   \n\n       rAckDelayMin  sAckDelayAvg  rAckDelayAvg  \n0               0.0      0.000219      0.031154  \n1               0.0      0.000126      0.027727  \n2               0.0      0.023117      0.030055  \n3               0.0      0.020180      0.028530  \n4               0.0      0.000094      0.017102  \n...             ...           ...           ...  \n45713           NaN      0.000007           NaN  \n45714           NaN           NaN           NaN  \n45715           NaN           NaN           NaN  \n45716           NaN           NaN           NaN  \n45717           NaN           NaN           NaN  \n\n[45718 rows x 60 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sAddress</th>\n      <th>rAddress</th>\n      <th>sMACs</th>\n      <th>rMACs</th>\n      <th>sIPs</th>\n      <th>rIPs</th>\n      <th>protocol</th>\n      <th>startDate</th>\n      <th>endDate</th>\n      <th>start</th>\n      <th>...</th>\n      <th>sWinTCP</th>\n      <th>rWinTCP</th>\n      <th>sFragmentRate</th>\n      <th>rFragmentRate</th>\n      <th>sAckDelayMax</th>\n      <th>rAckDelayMax</th>\n      <th>sAckDelayMin</th>\n      <th>rAckDelayMin</th>\n      <th>sAckDelayAvg</th>\n      <th>rAckDelayAvg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:39.510337</td>\n      <td>2022-09-16 11:14:40.010330</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>509.00</td>\n      <td>502.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001</td>\n      <td>0.497</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000219</td>\n      <td>0.031154</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>192.168.0.12</td>\n      <td>192.168.0.21</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>192.168.0.12</td>\n      <td>192.168.0.21</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:39.513421</td>\n      <td>2022-09-16 11:14:40.013394</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>509.00</td>\n      <td>502.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.497</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000126</td>\n      <td>0.027727</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:39.601160</td>\n      <td>2022-09-16 11:14:40.054139</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>503.05</td>\n      <td>506.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.198</td>\n      <td>0.200</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.023117</td>\n      <td>0.030055</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.12</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:40.200719</td>\n      <td>2022-09-16 11:14:40.602902</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>503.00</td>\n      <td>506.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.197</td>\n      <td>0.200</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.020180</td>\n      <td>0.028530</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.21</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 11:14:40.010348</td>\n      <td>2022-09-16 11:14:40.507654</td>\n      <td>1.663320e+09</td>\n      <td>...</td>\n      <td>509.00</td>\n      <td>502.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.493</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000094</td>\n      <td>0.017102</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45713</th>\n      <td>192.168.0.22</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:16</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.22</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-TCP</td>\n      <td>2022-09-16 13:23:30.589943</td>\n      <td>2022-09-16 13:23:30.877939</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>1024.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>0.000007</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45714</th>\n      <td>192.168.0.11</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:0b</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.11</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:01.401338</td>\n      <td>2022-09-16 13:11:01.401338</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45715</th>\n      <td>192.168.0.12</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:0c</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.12</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:01.401604</td>\n      <td>2022-09-16 13:11:01.401604</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45716</th>\n      <td>192.168.0.21</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:15</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.21</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:03.511387</td>\n      <td>2022-09-16 13:11:03.511387</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>45717</th>\n      <td>192.168.0.23</td>\n      <td>192.168.0.41</td>\n      <td>02:42:c0:a8:00:17</td>\n      <td>02:42:c0:a8:00:29</td>\n      <td>192.168.0.23</td>\n      <td>192.168.0.41</td>\n      <td>IPV4-ICMP</td>\n      <td>2022-09-16 13:11:05.744681</td>\n      <td>2022-09-16 13:11:05.744681</td>\n      <td>1.663327e+09</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>45718 rows × 60 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_column = ['NST_M_Label']\n",
    "label_columns_all = ['IT_B_Label', 'IT_M_Label', 'NST_B_Label', 'NST_M_Label']\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(data[label_column])\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_one_hot = pd.get_dummies(y_encoded).values\n",
    "\n",
    "# Drop all label columns\n",
    "data.drop(columns=label_columns_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - RISE\\Code Repo\\AnomalyDetection\\Interpreter\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class columnDropperTransformer():\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        return X.drop(self.columns,axis=1)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "unused_columns = ['sAddress', 'rAddress', 'sMACs', 'rMACs', 'sIPs', 'rIPs', 'startDate', 'endDate', 'start', 'end', 'startOffset', 'endOffset']\n",
    "categorical_columns = ['protocol']\n",
    "\n",
    "# num_columns = data.select_dtypes(np.number).columns.tolist()\n",
    "# cat_columns = data.select_dtypes('object').columns.tolist()\n",
    "\n",
    "pipeline_categorial = ColumnTransformer(\n",
    "    [\n",
    "        ('ohe_encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'),[0])\n",
    "    ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('dropper' , columnDropperTransformer(unused_columns)),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('col_tra_2',pipeline_categorial),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y_one_hot, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.transform(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.977580927384077\n",
      "Confusion Matrix:\n",
      "[[7325    0    3    6    6    1]\n",
      " [   0  387    0    0    0    0]\n",
      " [   0    0   32    3    3    0]\n",
      " [   5    0   18  489    1    4]\n",
      " [  20    0   32   12  324    1]\n",
      " [  43    0    7   39    1  382]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.estimator import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "def create_model(input_dim, output_dim, hidden_layer_size=64, alpha=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_size, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model, input_dim=X_train.shape[1], output_dim=y_train.shape[1], epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Inverse transform one-hot encoded predictions to original labels\n",
    "# y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred_classes)\n",
    "conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred_classes)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Develop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3565 - accuracy: 0.9012 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1465 - accuracy: 0.9546 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1128 - accuracy: 0.9634 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0944 - accuracy: 0.9657 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0818 - accuracy: 0.9697 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0736 - accuracy: 0.9751 - 999ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0679 - accuracy: 0.9768 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0638 - accuracy: 0.9769 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0610 - accuracy: 0.9776 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0590 - accuracy: 0.9779 - 1s/epoch - 1ms/step\n",
      "381/381 - 1s - 507ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=32; total time=  12.5s\n",
      "Epoch 1/10\n",
      "762/762 - 3s - loss: 0.3266 - accuracy: 0.9095 - 3s/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 2s - loss: 0.1488 - accuracy: 0.9527 - 2s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1182 - accuracy: 0.9620 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0990 - accuracy: 0.9629 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 2s - loss: 0.0856 - accuracy: 0.9660 - 2s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0772 - accuracy: 0.9711 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 2s - loss: 0.0700 - accuracy: 0.9738 - 2s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0658 - accuracy: 0.9756 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0629 - accuracy: 0.9763 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0605 - accuracy: 0.9771 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 829ms/epoch - 2ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=32; total time=  16.5s\n",
      "Epoch 1/10\n",
      "762/762 - 3s - loss: 0.3518 - accuracy: 0.9024 - 3s/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1495 - accuracy: 0.9533 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 2s - loss: 0.1160 - accuracy: 0.9622 - 2s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 2s - loss: 0.0994 - accuracy: 0.9630 - 2s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 2s - loss: 0.0879 - accuracy: 0.9656 - 2s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 2s - loss: 0.0801 - accuracy: 0.9706 - 2s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 2s - loss: 0.0742 - accuracy: 0.9731 - 2s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 2s - loss: 0.0707 - accuracy: 0.9758 - 2s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 2s - loss: 0.0660 - accuracy: 0.9756 - 2s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0640 - accuracy: 0.9763 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 566ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=32; total time=  20.5s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2916 - accuracy: 0.9126 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1270 - accuracy: 0.9612 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0992 - accuracy: 0.9648 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0822 - accuracy: 0.9692 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0714 - accuracy: 0.9750 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0652 - accuracy: 0.9770 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0611 - accuracy: 0.9774 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0592 - accuracy: 0.9781 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0571 - accuracy: 0.9781 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0557 - accuracy: 0.9785 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 506ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=64; total time=  13.6s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2835 - accuracy: 0.9167 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1284 - accuracy: 0.9603 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1009 - accuracy: 0.9624 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0841 - accuracy: 0.9674 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0742 - accuracy: 0.9731 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0680 - accuracy: 0.9749 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0647 - accuracy: 0.9761 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0615 - accuracy: 0.9758 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0587 - accuracy: 0.9763 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0575 - accuracy: 0.9774 - 1s/epoch - 1ms/step\n",
      "381/381 - 1s - 517ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=64; total time=  13.1s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2566 - accuracy: 0.9212 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1201 - accuracy: 0.9605 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0935 - accuracy: 0.9646 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 2s - loss: 0.0788 - accuracy: 0.9717 - 2s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 2s - loss: 0.0702 - accuracy: 0.9758 - 2s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0660 - accuracy: 0.9751 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0628 - accuracy: 0.9770 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0612 - accuracy: 0.9773 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0599 - accuracy: 0.9779 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0572 - accuracy: 0.9775 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 535ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=64; total time=  15.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2147 - accuracy: 0.9376 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1065 - accuracy: 0.9632 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0824 - accuracy: 0.9694 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0700 - accuracy: 0.9764 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0635 - accuracy: 0.9775 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0601 - accuracy: 0.9774 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0570 - accuracy: 0.9782 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0560 - accuracy: 0.9793 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0552 - accuracy: 0.9788 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0534 - accuracy: 0.9799 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 535ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=128; total time=  13.9s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2361 - accuracy: 0.9301 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1113 - accuracy: 0.9625 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0867 - accuracy: 0.9667 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0741 - accuracy: 0.9743 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0670 - accuracy: 0.9753 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0629 - accuracy: 0.9762 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0608 - accuracy: 0.9757 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0571 - accuracy: 0.9775 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0551 - accuracy: 0.9780 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0550 - accuracy: 0.9781 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 622ms/epoch - 2ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=128; total time=  13.1s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2278 - accuracy: 0.9341 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1115 - accuracy: 0.9610 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0846 - accuracy: 0.9683 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0728 - accuracy: 0.9749 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0672 - accuracy: 0.9747 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0625 - accuracy: 0.9767 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0607 - accuracy: 0.9771 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0603 - accuracy: 0.9778 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0564 - accuracy: 0.9776 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0537 - accuracy: 0.9777 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 562ms/epoch - 1ms/step\n",
      "[CV] END model__activation=relu, model__hidden_layer_size=128; total time=  13.2s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3431 - accuracy: 0.9032 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1422 - accuracy: 0.9555 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 2s - loss: 0.1058 - accuracy: 0.9630 - 2s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0889 - accuracy: 0.9676 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0784 - accuracy: 0.9738 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0724 - accuracy: 0.9748 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0682 - accuracy: 0.9763 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0644 - accuracy: 0.9770 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0619 - accuracy: 0.9774 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0595 - accuracy: 0.9790 - 1s/epoch - 1ms/step\n",
      "381/381 - 0s - 428ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=32; total time=  14.6s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3363 - accuracy: 0.9092 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1450 - accuracy: 0.9536 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1048 - accuracy: 0.9633 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0864 - accuracy: 0.9714 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0771 - accuracy: 0.9736 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0709 - accuracy: 0.9746 - 905ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0669 - accuracy: 0.9760 - 888ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0635 - accuracy: 0.9765 - 835ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0611 - accuracy: 0.9769 - 851ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0593 - accuracy: 0.9784 - 858ms/epoch - 1ms/step\n",
      "381/381 - 0s - 426ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=32; total time=  11.2s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3292 - accuracy: 0.9073 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1503 - accuracy: 0.9513 - 729ms/epoch - 956us/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1110 - accuracy: 0.9624 - 810ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0903 - accuracy: 0.9681 - 855ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0800 - accuracy: 0.9726 - 861ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0732 - accuracy: 0.9748 - 800ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0684 - accuracy: 0.9749 - 767ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0649 - accuracy: 0.9763 - 847ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0625 - accuracy: 0.9768 - 904ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0604 - accuracy: 0.9774 - 780ms/epoch - 1ms/step\n",
      "381/381 - 0s - 337ms/epoch - 885us/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=32; total time=   9.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2655 - accuracy: 0.9215 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1231 - accuracy: 0.9582 - 824ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0926 - accuracy: 0.9676 - 940ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0777 - accuracy: 0.9734 - 958ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0685 - accuracy: 0.9772 - 817ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0640 - accuracy: 0.9779 - 935ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0607 - accuracy: 0.9781 - 888ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0581 - accuracy: 0.9785 - 792ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0571 - accuracy: 0.9794 - 767ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0555 - accuracy: 0.9801 - 822ms/epoch - 1ms/step\n",
      "381/381 - 0s - 337ms/epoch - 885us/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=64; total time=   9.8s\n",
      "Epoch 1/10\n",
      "762/762 - 1s - loss: 0.2718 - accuracy: 0.9187 - 1s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1241 - accuracy: 0.9578 - 759ms/epoch - 996us/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0917 - accuracy: 0.9669 - 768ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0775 - accuracy: 0.9726 - 779ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0699 - accuracy: 0.9753 - 785ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0646 - accuracy: 0.9760 - 782ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0617 - accuracy: 0.9763 - 773ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0593 - accuracy: 0.9774 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0574 - accuracy: 0.9780 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 2s - loss: 0.0560 - accuracy: 0.9783 - 2s/epoch - 3ms/step\n",
      "381/381 - 1s - 1s/epoch - 3ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=64; total time=  11.9s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2680 - accuracy: 0.9225 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1192 - accuracy: 0.9590 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0897 - accuracy: 0.9678 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0762 - accuracy: 0.9741 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0690 - accuracy: 0.9756 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0646 - accuracy: 0.9767 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0617 - accuracy: 0.9770 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0601 - accuracy: 0.9774 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0576 - accuracy: 0.9785 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0567 - accuracy: 0.9778 - 1s/epoch - 1ms/step\n",
      "381/381 - 1s - 744ms/epoch - 2ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=64; total time=  14.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2416 - accuracy: 0.9288 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1110 - accuracy: 0.9612 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0846 - accuracy: 0.9716 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0735 - accuracy: 0.9744 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0665 - accuracy: 0.9770 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0629 - accuracy: 0.9770 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0606 - accuracy: 0.9776 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 2s - loss: 0.0575 - accuracy: 0.9791 - 2s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0553 - accuracy: 0.9792 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0544 - accuracy: 0.9785 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 538ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=128; total time=  14.1s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2382 - accuracy: 0.9288 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1079 - accuracy: 0.9616 - 1s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.0831 - accuracy: 0.9714 - 1s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0721 - accuracy: 0.9751 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0675 - accuracy: 0.9746 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0624 - accuracy: 0.9774 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0607 - accuracy: 0.9765 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0581 - accuracy: 0.9773 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0569 - accuracy: 0.9772 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0557 - accuracy: 0.9769 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 520ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=128; total time=  14.4s\n",
      "Epoch 1/10\n",
      "762/762 - 3s - loss: 0.2383 - accuracy: 0.9287 - 3s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 2s - loss: 0.1099 - accuracy: 0.9614 - 2s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 2s - loss: 0.0850 - accuracy: 0.9699 - 2s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.0742 - accuracy: 0.9731 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0680 - accuracy: 0.9753 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0640 - accuracy: 0.9759 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0610 - accuracy: 0.9768 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0591 - accuracy: 0.9776 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0569 - accuracy: 0.9781 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0557 - accuracy: 0.9779 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 536ms/epoch - 1ms/step\n",
      "[CV] END model__activation=tanh, model__hidden_layer_size=128; total time=  16.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.4200 - accuracy: 0.8833 - 2s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2195 - accuracy: 0.9312 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1827 - accuracy: 0.9340 - 909ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1564 - accuracy: 0.9453 - 949ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1348 - accuracy: 0.9544 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1169 - accuracy: 0.9605 - 910ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.1029 - accuracy: 0.9637 - 965ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0924 - accuracy: 0.9652 - 854ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0846 - accuracy: 0.9695 - 921ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0787 - accuracy: 0.9733 - 920ms/epoch - 1ms/step\n",
      "381/381 - 0s - 386ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=32; total time=  11.5s\n",
      "Epoch 1/10\n",
      "762/762 - 1s - loss: 0.4809 - accuracy: 0.8587 - 1s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2245 - accuracy: 0.9316 - 842ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1883 - accuracy: 0.9347 - 999ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1605 - accuracy: 0.9433 - 992ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1355 - accuracy: 0.9556 - 973ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1153 - accuracy: 0.9614 - 865ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.1002 - accuracy: 0.9626 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0893 - accuracy: 0.9658 - 870ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0820 - accuracy: 0.9701 - 948ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0766 - accuracy: 0.9733 - 961ms/epoch - 1ms/step\n",
      "381/381 - 0s - 393ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=32; total time=  10.4s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.4377 - accuracy: 0.8768 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2264 - accuracy: 0.9304 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1858 - accuracy: 0.9343 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1576 - accuracy: 0.9466 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1344 - accuracy: 0.9556 - 929ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1154 - accuracy: 0.9611 - 898ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.1015 - accuracy: 0.9635 - 872ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0912 - accuracy: 0.9652 - 941ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0839 - accuracy: 0.9701 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0786 - accuracy: 0.9736 - 984ms/epoch - 1ms/step\n",
      "381/381 - 0s - 437ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=32; total time=  11.1s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3476 - accuracy: 0.8956 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1982 - accuracy: 0.9329 - 980ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1633 - accuracy: 0.9412 - 978ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1356 - accuracy: 0.9543 - 1s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1133 - accuracy: 0.9614 - 1s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0974 - accuracy: 0.9649 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0867 - accuracy: 0.9686 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0792 - accuracy: 0.9723 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0736 - accuracy: 0.9748 - 920ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0698 - accuracy: 0.9763 - 869ms/epoch - 1ms/step\n",
      "381/381 - 0s - 430ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=64; total time=  12.0s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.3479 - accuracy: 0.8981 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1974 - accuracy: 0.9336 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1625 - accuracy: 0.9393 - 958ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1356 - accuracy: 0.9535 - 997ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1140 - accuracy: 0.9609 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0986 - accuracy: 0.9639 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0877 - accuracy: 0.9662 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0803 - accuracy: 0.9717 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0754 - accuracy: 0.9738 - 934ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0712 - accuracy: 0.9738 - 953ms/epoch - 1ms/step\n",
      "381/381 - 0s - 415ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=64; total time=  11.7s\n",
      "Epoch 1/10\n",
      "762/762 - 1s - loss: 0.3862 - accuracy: 0.8780 - 1s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.2032 - accuracy: 0.9323 - 838ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1730 - accuracy: 0.9356 - 903ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1477 - accuracy: 0.9486 - 834ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1256 - accuracy: 0.9578 - 877ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.1076 - accuracy: 0.9624 - 863ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0943 - accuracy: 0.9652 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0849 - accuracy: 0.9688 - 892ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0783 - accuracy: 0.9722 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0734 - accuracy: 0.9741 - 941ms/epoch - 1ms/step\n",
      "381/381 - 0s - 425ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=64; total time=  10.3s\n",
      "Epoch 1/10\n",
      "762/762 - 1s - loss: 0.2826 - accuracy: 0.9142 - 1s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1761 - accuracy: 0.9353 - 902ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1424 - accuracy: 0.9507 - 877ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1166 - accuracy: 0.9596 - 896ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.0986 - accuracy: 0.9644 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0864 - accuracy: 0.9696 - 943ms/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0782 - accuracy: 0.9736 - 946ms/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0736 - accuracy: 0.9754 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0695 - accuracy: 0.9756 - 967ms/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0660 - accuracy: 0.9765 - 922ms/epoch - 1ms/step\n",
      "381/381 - 0s - 485ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=128; total time=  10.7s\n",
      "Epoch 1/10\n",
      "762/762 - 1s - loss: 0.3191 - accuracy: 0.9010 - 1s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1876 - accuracy: 0.9334 - 956ms/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1533 - accuracy: 0.9452 - 925ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1251 - accuracy: 0.9564 - 946ms/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1042 - accuracy: 0.9621 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0903 - accuracy: 0.9661 - 1s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0811 - accuracy: 0.9706 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0751 - accuracy: 0.9733 - 994ms/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0708 - accuracy: 0.9741 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0676 - accuracy: 0.9756 - 1s/epoch - 2ms/step\n",
      "381/381 - 0s - 496ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=128; total time=  11.6s\n",
      "Epoch 1/10\n",
      "762/762 - 2s - loss: 0.2886 - accuracy: 0.9103 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "762/762 - 1s - loss: 0.1824 - accuracy: 0.9329 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "762/762 - 1s - loss: 0.1482 - accuracy: 0.9487 - 905ms/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "762/762 - 1s - loss: 0.1226 - accuracy: 0.9582 - 1s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "762/762 - 1s - loss: 0.1042 - accuracy: 0.9612 - 926ms/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "762/762 - 1s - loss: 0.0907 - accuracy: 0.9658 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "762/762 - 1s - loss: 0.0817 - accuracy: 0.9703 - 1s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "762/762 - 1s - loss: 0.0760 - accuracy: 0.9731 - 1s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "762/762 - 1s - loss: 0.0715 - accuracy: 0.9744 - 1s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "762/762 - 1s - loss: 0.0682 - accuracy: 0.9749 - 1s/epoch - 2ms/step\n",
      "381/381 - 1s - 545ms/epoch - 1ms/step\n",
      "[CV] END model__activation=sigmoid, model__hidden_layer_size=128; total time=  13.0s\n",
      "Epoch 1/10\n",
      "1143/1143 - 2s - loss: 0.1947 - accuracy: 0.9428 - 2s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "1143/1143 - 1s - loss: 0.0938 - accuracy: 0.9659 - 1s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "1143/1143 - 1s - loss: 0.0740 - accuracy: 0.9736 - 1s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "1143/1143 - 2s - loss: 0.0649 - accuracy: 0.9765 - 2s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "1143/1143 - 1s - loss: 0.0597 - accuracy: 0.9774 - 1s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "1143/1143 - 1s - loss: 0.0570 - accuracy: 0.9780 - 1s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "1143/1143 - 1s - loss: 0.0559 - accuracy: 0.9776 - 1s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "1143/1143 - 1s - loss: 0.0534 - accuracy: 0.9786 - 1s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "1143/1143 - 1s - loss: 0.0547 - accuracy: 0.9783 - 1s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "1143/1143 - 1s - loss: 0.0504 - accuracy: 0.9789 - 1s/epoch - 1ms/step\n",
      "Best Hyperparameters: {'model__activation': 'relu', 'model__hidden_layer_size': 128}\n",
      "286/286 - 0s - 340ms/epoch - 1ms/step\n",
      "Test Accuracy: 0.9787839020122485\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.estimator import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "def create_model(input_dim, output_dim, hidden_layer_size=64, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_size, input_dim=input_dim, activation=activation))\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    # optimizer = keras.optimizers.Adam(learning_rate= alpha)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model, input_dim=X_train.shape[1], output_dim=y_train.shape[1], epochs=10, batch_size=32, verbose=2)\n",
    "param_grid = {\n",
    "    'model__hidden_layer_size': [32, 64, 128],\n",
    "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    # 'model__alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_result.best_params_}\")\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Inverse transform one-hot encoded predictions to original labels\n",
    "# y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = accuracy_score(y_test.argmax(axis=1), y_pred_classes)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmpxkjd9ogc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmpxkjd9ogc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmpflwify18\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ALIREZ~1\\AppData\\Local\\Temp\\tmpflwify18\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": "['output/predict.joblib']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from keras.models import load_model\n",
    "\n",
    "# Assuming 'model' is your Keras model\n",
    "joblib.dump(best_model, 'output/keras_classifier_model.joblib')\n",
    "predict_pipeline = Pipeline([\n",
    "    ('col_tra_2',preprocess),\n",
    "    ('model' , best_model)\n",
    "])\n",
    "joblib.dump(predict_pipeline, 'output/predict.joblib')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}